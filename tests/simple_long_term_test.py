#!/usr/bin/env python3
"""
Simple Long-term Memory Systems Test

Demonstrates the key concepts of the new long-term memory and relationship tracking systems.
"""

import sqlite3
import json
from datetime import datetime, timedelta
from pathlib import Path
import hashlib

def create_memory_archiving_demo():
    """Demonstrate memory archiving system concepts."""
    print("üì¶ Memory Archiving System Demo")
    print("-" * 40)
    
    # Create demo archive database
    archive_db = Path("demo_archive.db")
    
    with sqlite3.connect(archive_db) as conn:
        cursor = conn.cursor()
        
        # Create archive table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS archived_memories (
                id TEXT PRIMARY KEY,
                original_id TEXT NOT NULL,
                content TEXT NOT NULL,
                compressed_content TEXT,
                memory_type TEXT NOT NULL,
                user_id TEXT NOT NULL,
                character_id TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                archived_at TEXT NOT NULL,
                importance_score REAL NOT NULL,
                recovery_priority REAL DEFAULT 0.5
            )
        """)
        
        # Demo: Archive some important memories
        demo_memories = [
            {
                "id": "mem_001",
                "content": "I told you about my sister Sarah getting married next month. I'm really excited but nervous about giving a speech.",
                "memory_type": "relationship",
                "importance_score": 0.8,
                "user_id": "user_123",
                "character_id": "character_456"
            },
            {
                "id": "mem_002", 
                "content": "You helped me decide to take the job promotion. I really trust your advice and appreciate our friendship.",
                "memory_type": "emotional",
                "importance_score": 0.9,
                "user_id": "user_123",
                "character_id": "character_456"
            }
        ]
        
        for memory in demo_memories:
            # Compress content (simple version)
            content = memory["content"]
            compressed = content[:50] + "... [ARCHIVED] ..." + content[-30:]
            
            cursor.execute("""
                INSERT INTO archived_memories 
                (id, original_id, content, compressed_content, memory_type, user_id, character_id,
                 timestamp, archived_at, importance_score, recovery_priority)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                f"arch_{memory['id']}",
                memory["id"],
                content,
                compressed,
                memory["memory_type"],
                memory["user_id"],
                memory["character_id"],
                datetime.now().isoformat(),
                datetime.now().isoformat(),
                memory["importance_score"],
                0.8 if memory["importance_score"] > 0.7 else 0.5
            ))
        
        conn.commit()
        
        # Show archived memories
        cursor.execute("SELECT * FROM archived_memories")
        archived = cursor.fetchall()
        
        print(f"‚úÖ Archived {len(archived)} memories")
        for memory in archived:
            print(f"  üìù {memory[1]}: {memory[3][:60]}... (Priority: {memory[10]:.1f})")
    
    return archive_db

def create_relationship_persistence_demo():
    """Demonstrate relationship persistence system concepts."""
    print("\nüíï Relationship Persistence System Demo")
    print("-" * 40)
    
    # Create demo persistence database
    persistence_db = Path("demo_persistence.db")
    
    with sqlite3.connect(persistence_db) as conn:
        cursor = conn.cursor()
        
        # Create relationship snapshots table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS relationship_snapshots (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                character_id TEXT NOT NULL,
                relationship_level REAL NOT NULL,
                relationship_state TEXT NOT NULL,
                trust_level REAL NOT NULL,
                emotional_bond REAL NOT NULL,
                shared_experiences INTEGER NOT NULL,
                inside_jokes TEXT,
                personal_secrets TEXT,
                last_interaction TEXT NOT NULL,
                relationship_age_days INTEGER NOT NULL,
                continuity_score REAL NOT NULL,
                snapshot_timestamp TEXT NOT NULL
            )
        """)
        
        # Demo: Create relationship snapshots over time
        snapshots = [
            {
                "level": 2.0,
                "trust": 0.6,
                "emotional": 0.5,
                "experiences": 5,
                "jokes": ["Remember that time with the coffee?"],
                "secrets": ["I'm nervous about public speaking"],
                "age_days": 7
            },
            {
                "level": 4.0,
                "trust": 0.8,
                "emotional": 0.7,
                "experiences": 15,
                "jokes": ["Remember that time with the coffee?", "The promotion celebration"],
                "secrets": ["I'm nervous about public speaking", "I'm thinking of moving"],
                "age_days": 30
            },
            {
                "level": 6.0,
                "trust": 0.9,
                "emotional": 0.8,
                "experiences": 25,
                "jokes": ["Remember that time with the coffee?", "The promotion celebration", "The wedding speech"],
                "secrets": ["I'm nervous about public speaking", "I'm thinking of moving", "I love our friendship"],
                "age_days": 90
            }
        ]
        
        for i, snapshot in enumerate(snapshots):
            cursor.execute("""
                INSERT INTO relationship_snapshots 
                (id, user_id, character_id, relationship_level, relationship_state, trust_level,
                 emotional_bond, shared_experiences, inside_jokes, personal_secrets,
                 last_interaction, relationship_age_days, continuity_score, snapshot_timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                f"snap_{i+1}",
                "user_123",
                "character_456",
                snapshot["level"],
                "friend" if snapshot["level"] < 5 else "close_friend",
                snapshot["trust"],
                snapshot["emotional"],
                snapshot["experiences"],
                json.dumps(snapshot["jokes"]),
                json.dumps(snapshot["secrets"]),
                datetime.now().isoformat(),
                snapshot["age_days"],
                min(1.0, snapshot["level"] / 10.0),
                datetime.now().isoformat()
            ))
        
        conn.commit()
        
        # Show relationship evolution
        cursor.execute("SELECT relationship_level, trust_level, emotional_bond, shared_experiences FROM relationship_snapshots ORDER BY snapshot_timestamp")
        evolution = cursor.fetchall()
        
        print(f"‚úÖ Tracked relationship evolution over {len(evolution)} snapshots")
        for i, (level, trust, emotional, experiences) in enumerate(evolution):
            print(f"  üì∏ Snapshot {i+1}: Level {level:.1f}, Trust {trust:.1f}, Bond {emotional:.1f}, Experiences {experiences}")
    
    return persistence_db

def create_smart_compression_demo():
    """Demonstrate smart compression system concepts."""
    print("\nüóúÔ∏è Smart Compression System Demo")
    print("-" * 40)
    
    # Create demo compression database
    compression_db = Path("demo_compression.db")
    
    with sqlite3.connect(compression_db) as conn:
        cursor = conn.cursor()
        
        # Create compression history table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS compression_history (
                id TEXT PRIMARY KEY,
                original_content TEXT NOT NULL,
                compressed_content TEXT NOT NULL,
                compression_ratio REAL NOT NULL,
                compression_type TEXT NOT NULL,
                preserved_elements TEXT,
                importance_preserved REAL NOT NULL,
                relationship_context_preserved BOOLEAN NOT NULL
            )
        """)
        
        # Demo: Compress different types of memories
        demo_memories = [
            {
                "content": "I'm so happy to see you again! I've been thinking about our conversation from last week about my family. My sister Sarah is getting married next month, and I'm really excited but also nervous about giving a speech at the wedding. You always give such good advice, and I really trust your opinion on these things.",
                "type": "relationship_focused",
                "importance": 0.8
            },
            {
                "content": "I'm feeling really anxious today because of work stress. The project deadline is approaching and I'm worried I won't meet it. I've been having trouble sleeping and my stomach is in knots. I just needed to talk to someone about it.",
                "type": "emotional_focused", 
                "importance": 0.6
            },
            {
                "content": "The weather is nice today. I went for a walk in the park and saw some birds. It was a pleasant afternoon.",
                "type": "semantic",
                "importance": 0.3
            }
        ]
        
        for i, memory in enumerate(demo_memories):
            # Apply different compression strategies
            if memory["type"] == "relationship_focused":
                # Keep relationship keywords
                compressed = "I'm happy to see you! We talked about my family - my sister Sarah is getting married. I trust your advice about the wedding speech."
                preserved = ["relationship_keywords", "family_entities", "trust_context"]
            elif memory["type"] == "emotional_focused":
                # Keep emotional context
                compressed = "I'm feeling anxious about work stress and project deadline. Having trouble sleeping and stomach issues."
                preserved = ["emotional_keywords", "stress_context"]
            else:
                # Simple compression
                compressed = "Weather is nice. Went for a walk in the park."
                preserved = ["basic_info"]
            
            compression_ratio = len(compressed) / len(memory["content"])
            importance_preserved = memory["importance"] * (0.9 if "relationship" in memory["type"] else 0.7)
            relationship_preserved = "relationship" in memory["type"]
            
            cursor.execute("""
                INSERT INTO compression_history 
                (id, original_content, compressed_content, compression_ratio, compression_type,
                 preserved_elements, importance_preserved, relationship_context_preserved)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                f"comp_{i+1}",
                memory["content"],
                compressed,
                compression_ratio,
                memory["type"],
                json.dumps(preserved),
                importance_preserved,
                relationship_preserved
            ))
        
        conn.commit()
        
        # Show compression results
        cursor.execute("SELECT compression_type, compression_ratio, importance_preserved, relationship_context_preserved FROM compression_history")
        compressions = cursor.fetchall()
        
        print(f"‚úÖ Compressed {len(compressions)} memories")
        for comp_type, ratio, importance, relationship in compressions:
            print(f"  üóúÔ∏è {comp_type}: {ratio:.1%} size, {importance:.1f} importance preserved, relationship: {relationship}")
    
    return compression_db

def create_database_optimization_demo():
    """Demonstrate database optimization concepts."""
    print("\nüîß Database Optimization Demo")
    print("-" * 40)
    
    # Create demo optimized database
    optimized_db = Path("demo_optimized.db")
    
    with sqlite3.connect(optimized_db) as conn:
        cursor = conn.cursor()
        
        # Create optimized memory table with indexes
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS optimized_memories (
                id TEXT PRIMARY KEY,
                content TEXT NOT NULL,
                user_id TEXT NOT NULL,
                character_id TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                importance_score REAL NOT NULL,
                memory_type TEXT NOT NULL,
                archive_status TEXT DEFAULT 'active'
            )
        """)
        
        # Create performance indexes
        indexes = [
            ("idx_user_char", "user_id, character_id"),
            ("idx_timestamp", "timestamp DESC"),
            ("idx_importance", "importance_score DESC"),
            ("idx_type", "memory_type"),
            ("idx_archive", "archive_status")
        ]
        
        for index_name, columns in indexes:
            cursor.execute(f"CREATE INDEX IF NOT EXISTS {index_name} ON optimized_memories ({columns})")
        
        # Insert demo data
        for i in range(1000):
            cursor.execute("""
                INSERT INTO optimized_memories 
                (id, content, user_id, character_id, timestamp, importance_score, memory_type)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                f"mem_{i:04d}",
                f"Memory content {i} with some relationship context and emotional details.",
                "user_123",
                "character_456",
                (datetime.now() - timedelta(days=i)).isoformat(),
                0.3 + (i % 10) * 0.1,
                "relationship" if i % 3 == 0 else "general"
            ))
        
        conn.commit()
        
        # Analyze performance
        cursor.execute("ANALYZE")
        
        # Show optimization results
        cursor.execute("SELECT COUNT(*) FROM optimized_memories")
        total_memories = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM optimized_memories WHERE archive_status = 'active'")
        active_memories = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(importance_score) FROM optimized_memories")
        avg_importance = cursor.fetchone()[0]
        
        print(f"‚úÖ Optimized database with {total_memories} memories")
        print(f"  üìä Active memories: {active_memories}")
        print(f"  ‚≠ê Average importance: {avg_importance:.2f}")
        print(f"  üîç Performance indexes: {len(indexes)}")
        
        # Demonstrate fast queries
        import time
        start_time = time.time()
        cursor.execute("SELECT * FROM optimized_memories WHERE user_id = ? AND character_id = ? ORDER BY timestamp DESC LIMIT 10", 
                      ("user_123", "character_456"))
        results = cursor.fetchall()
        query_time = time.time() - start_time
        
        print(f"  ‚ö° Fast query time: {query_time:.3f}s for {len(results)} results")
    
    return optimized_db

def demonstrate_long_term_benefits():
    """Demonstrate the benefits of long-term tracking."""
    print("\nüéØ Long-term Relationship Tracking Benefits")
    print("=" * 50)
    
    benefits = [
        {
            "benefit": "Memory Archiving",
            "description": "Old but important memories are preserved for long-term access",
            "example": "User returns after 6 months, system recalls their sister's wedding and job promotion",
            "impact": "Maintains relationship continuity across long periods"
        },
        {
            "benefit": "Relationship Persistence", 
            "description": "Relationship strength tracked independently of interaction frequency",
            "example": "Strong friendship maintained even if user takes breaks from chatting",
            "impact": "Prevents relationship decay during inactivity"
        },
        {
            "benefit": "Smart Compression",
            "description": "AI-like summarization preserves important context while reducing storage",
            "example": "Long conversation about family issues compressed to key relationship points",
            "impact": "Efficient storage without losing important details"
        },
        {
            "benefit": "Relationship Recovery",
            "description": "Mechanisms to rebuild relationship context from archived data",
            "example": "System recovers relationship state and important memories after long absence",
            "impact": "Seamless experience after extended breaks"
        },
        {
            "benefit": "Database Optimization",
            "description": "Proper indexing and archiving for large datasets",
            "example": "Fast queries even with thousands of memories and relationships",
            "impact": "Scalable performance for long-term use"
        },
        {
            "benefit": "Relationship Continuity",
            "description": "Tracks relationship strength independently of interaction frequency",
            "example": "Relationship level maintained based on quality, not just quantity of interactions",
            "impact": "More meaningful relationship progression"
        }
    ]
    
    for i, benefit in enumerate(benefits, 1):
        print(f"\n{i}. {benefit['benefit']}")
        print(f"   üìù {benefit['description']}")
        print(f"   üí° Example: {benefit['example']}")
        print(f"   üéØ Impact: {benefit['impact']}")
    
    print(f"\nüîÆ These improvements enable the system to:")
    print("  ‚Ä¢ Maintain context across hundreds of sessions")
    print("  ‚Ä¢ Preserve important relationship details over time") 
    print("  ‚Ä¢ Recover relationship context after long periods of inactivity")
    print("  ‚Ä¢ Handle large datasets efficiently")
    print("  ‚Ä¢ Provide consistent relationship experiences")
    print("  ‚Ä¢ Scale to support long-term user relationships")

def main():
    """Run the complete long-term systems demonstration."""
    print("üß† Long-term Memory and Relationship Systems Demonstration")
    print("=" * 60)
    
    try:
        # Create demos
        archive_db = create_memory_archiving_demo()
        persistence_db = create_relationship_persistence_demo()
        compression_db = create_smart_compression_demo()
        optimized_db = create_database_optimization_demo()
        
        # Demonstrate benefits
        demonstrate_long_term_benefits()
        
        print(f"\nüéâ Demonstration completed successfully!")
        print(f"üìÅ Demo databases created:")
        print(f"  üì¶ {archive_db}")
        print(f"  üíï {persistence_db}")
        print(f"  üóúÔ∏è {compression_db}")
        print(f"  üîß {optimized_db}")
        
        # Cleanup demo files
        for db_file in [archive_db, persistence_db, compression_db, optimized_db]:
            if db_file.exists():
                db_file.unlink()
        
        print(f"\nüßπ Demo files cleaned up")
        
    except Exception as e:
        print(f"‚ùå Error during demonstration: {e}")

if __name__ == "__main__":
    main() 